{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/1000 [00:02<46:24,  2.79s/it]\u001b[A\n",
      "  0%|          | 2/1000 [00:05<45:59,  2.77s/it]\u001b[A\n",
      "  0%|          | 3/1000 [00:08<45:40,  2.75s/it]\u001b[A\n",
      "  0%|          | 4/1000 [00:10<45:22,  2.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.4391006827354431 occured at 4...\n",
      "Minimum loss occured at 4... \n",
      "Maximum QWK metric of 0.4511677324771881 occured at 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<43:59,  2.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/1000 [00:05<44:03,  2.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.33313632011413574 occured at 2...\n",
      "Minimum loss occured at 2... \n",
      "Maximum QWK metric of 0.08528832346200943 occured at 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<44:26,  2.67s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 2/1000 [00:05<44:49,  2.70s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.3620961308479309 occured at 2...\n",
      "Minimum loss occured at 2... \n",
      "Maximum QWK metric of 0.2737426161766052 occured at 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<43:43,  2.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/1000 [00:05<43:49,  2.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/1000 [00:07<43:53,  2.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/1000 [00:10<44:02,  2.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/1000 [00:13<44:10,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 6/1000 [00:15<44:15,  2.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 7/1000 [00:18<44:15,  2.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 8/1000 [00:21<44:19,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 9/1000 [00:24<44:20,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 10/1000 [00:26<44:12,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 11/1000 [00:29<44:20,  2.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.3657653331756592 occured at 8...\n",
      "Minimum loss occured at 11... \n",
      "Maximum QWK metric of 0.20535168051719666 occured at 8\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import hyp\n",
    "import models\n",
    "import state_data as aug\n",
    "import preprocess_data as prep\n",
    "\n",
    "def store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir):\n",
    "    most_acc = max(store_epoch_acc_val)\n",
    "    min_loss = min(store_epoch_loss_val)\n",
    "    qwk_max_loss = max(store_qwk_epoch_loss_val)\n",
    "    print(\"\\nHighest accuracy of {} occured at {}...\\nMinimum loss occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    with open(training_dir+\"/HYP.txt\",\"w+\") as f:\n",
    "        f.write(\"EPOCH = {} \\n\".format(hyp.EPOCHS))\n",
    "        f.write(\"LR = {} \\n\".format(hyp.LR))\n",
    "        f.write(\"HIDDEN_LAYERS = {} \\n\".format(HIDDEN))\n",
    "        f.write(\"ONE_HOT = {} \\n\".format(ONE_HOT))\n",
    "        f.write(\"DATA_AUG = {} \\n\".format(DATA_AUG))\n",
    "        f.write(\"Highest accuracy of {} occured at {}...\\nMinimum loss of {} occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        min_loss, store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    checkpoints = os.listdir(training_dir)\n",
    "    for checkpoint in checkpoints:\n",
    "        if \"checkpoint\" in checkpoint:\n",
    "            checkpoint_num = int(checkpoint[checkpoint.index(\"_\")+1:checkpoint.index(\".\")])\n",
    "            if checkpoint_num not in [store_qwk_epoch_loss_val.index(qwk_max_loss)+1,\n",
    "                                      store_epoch_loss_val.index(min_loss)+1,\n",
    "                                      store_epoch_acc_val.index(most_acc)+1]:\n",
    "                os.remove(training_dir+\"/\"+checkpoint)\n",
    "\n",
    "def train(model, HIDDEN, ONE_HOT, DATA_AUG, data_train_loader, data_val_loader):\n",
    "    print(\"Training...\")\n",
    "    training_dir = './training_{}+{}_{}_{}_{}'.format(ONE_HOT, DATA_AUG, len(HIDDEN), max(HIDDEN), time.time())\n",
    "    os.mkdir(training_dir)\n",
    "    os.mkdir(training_dir+'/misclassified')\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyp.LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    qwk_loss = cohen_kappa_score\n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    epoch = 0\n",
    "    store_epoch_loss = []\n",
    "    store_qwk_epoch_loss = []\n",
    "    store_epoch_loss_val = []\n",
    "    store_qwk_epoch_loss_val = []\n",
    "    store_epoch_acc_val = []\n",
    "    try:\n",
    "        for e in tqdm(range(hyp.EPOCHS)):\n",
    "            #scheduler.step()\n",
    "            epoch = e + 1\n",
    "            epoch_loss = 0\n",
    "            qwk_epoch_loss = 0\n",
    "            store_batch_loss = []\n",
    "            store_qwk_batch_loss = []\n",
    "            \n",
    "            for batch_num, (X, y) in enumerate(data_train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                batch_loss.backward()\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                optimizer.step()\n",
    "                store_batch_loss.append(batch_loss.clone().cpu())\n",
    "                store_qwk_batch_loss.append(qwk_batch_loss)\n",
    "                epoch_loss = torch.FloatTensor(store_batch_loss).mean()\n",
    "                qwk_epoch_loss = torch.FloatTensor(store_qwk_batch_loss).mean()\n",
    "                \n",
    "            store_epoch_loss.append(epoch_loss)\n",
    "            store_qwk_epoch_loss.append(qwk_epoch_loss)\n",
    "            torch.save(model.state_dict(), \"{}/checkpoint_{}.pth\".format(training_dir, epoch))\n",
    "\n",
    "            model.eval()\n",
    "            epoch_loss_val = 0\n",
    "            qwk_epoch_loss_val = 0\n",
    "            epoch_acc_val = 0\n",
    "            store_batch_loss_val = []\n",
    "            store_qwk_batch_loss_val = []\n",
    "            store_batch_acc_val = []\n",
    "            misclassified_images = []\n",
    "            for batch_num, (X, y) in enumerate(data_val_loader):\n",
    "                with torch.no_grad():\n",
    "                    prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                misclassified = prediction.max(-1)[-1].squeeze().cpu() != y.cpu()\n",
    "                misclassified_images.append(X[misclassified==1].cpu())\n",
    "                batch_acc = misclassified.float().mean()\n",
    "                store_batch_loss_val.append(batch_loss)\n",
    "                store_qwk_batch_loss_val.append(qwk_batch_loss)\n",
    "                store_batch_acc_val.append(batch_acc)\n",
    "                epoch_loss_val = torch.FloatTensor(store_batch_loss_val).mean()\n",
    "                qwk_epoch_loss_val = torch.FloatTensor(store_qwk_batch_loss_val).mean()\n",
    "                epoch_acc_val = torch.FloatTensor(store_batch_acc_val).mean()\n",
    "            store_epoch_loss_val.append(epoch_loss_val)\n",
    "            store_qwk_epoch_loss_val.append(qwk_epoch_loss_val)\n",
    "            store_epoch_acc_val.append(1-epoch_acc_val)\n",
    "            plt.plot(store_epoch_loss_val[1:], label=\"Validation Loss\")\n",
    "            plt.plot(store_qwk_epoch_loss_val[1:], label=\"Validation Metric(QWK)\")\n",
    "            plt.plot(store_epoch_acc_val[1:], label=\"Validation Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(\"{}/Loss.png\".format(training_dir))\n",
    "            plt.close()\n",
    "            if len(misclassified_images) > 0:\n",
    "                misclassified_images = np.concatenate(misclassified_images,axis=0)\n",
    "                validation_dir = training_dir+'/misclassified/checkpoint_{}'.format(epoch)\n",
    "                os.mkdir(validation_dir)\n",
    "            model.train()\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ONE_HOT in [0,1]: # for MaturitySize, FurLength, Health\n",
    "        for DATA_AUG in [0,1]: # for state data\n",
    "            data_train_loader, data_val_loader = prep.preprocess_data(ONE_HOT, DATA_AUG)\n",
    "            train(models.Model(hyp.HIDDEN_LIST[2], ONE_HOT, DATA_AUG).cuda(), hyp.HIDDEN_LIST[2], ONE_HOT, DATA_AUG, data_train_loader, data_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in main function: 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 0 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<44:39,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.3918193578720093 occured at 1...\n",
      "Minimum loss of 1.364376187324524 occured at 1... \n",
      "Maximum QWK metric of 0.28678271174430847 occured at 1\n",
      "in main function: 0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 0 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<43:26,  2.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.24059295654296875 occured at 1...\n",
      "Minimum loss of 1.531187653541565 occured at 1... \n",
      "Maximum QWK metric of -0.04076163470745087 occured at 1\n",
      "in main function: 1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 1 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<43:02,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.35421591997146606 occured at 1...\n",
      "Minimum loss of 1.3958059549331665 occured at 1... \n",
      "Maximum QWK metric of 0.26124417781829834 occured at 1\n",
      "in main function: 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 1 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<42:35,  2.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.29395681619644165 occured at 1...\n",
      "Minimum loss of 1.5496681928634644 occured at 1... \n",
      "Maximum QWK metric of -0.017652668058872223 occured at 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_v1]",
   "language": "python",
   "name": "conda-env-pytorch_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
