{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:05<49:19,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.3899478316307068 occured at 2...\n",
      "Minimum loss occured at 2... \n",
      "Maximum QWK metric of 0.33045652508735657 occured at 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:05<47:47,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.2976999282836914 occured at 1...\n",
      "Minimum loss occured at 1... \n",
      "Maximum QWK metric of 0.03216612711548805 occured at 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:05<45:49,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.39671987295150757 occured at 2...\n",
      "Minimum loss occured at 2... \n",
      "Maximum QWK metric of 0.33799639344215393 occured at 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:05<45:08,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.2771621346473694 occured at 1...\n",
      "Minimum loss occured at 2... \n",
      "Maximum QWK metric of 0.01687517948448658 occured at 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import hyp\n",
    "import models\n",
    "import state_data as aug\n",
    "import preprocess_data as prep\n",
    "\n",
    "def store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir):\n",
    "    most_acc = max(store_epoch_acc_val)\n",
    "    min_loss = min(store_epoch_loss_val)\n",
    "    qwk_max_loss = max(store_qwk_epoch_loss_val)\n",
    "    print(\"\\nHighest accuracy of {} occured at {}...\\nMinimum loss occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    with open(training_dir+\"/HYP.txt\",\"w+\") as f:\n",
    "        f.write(\"EPOCH = {} \\n\".format(hyp.EPOCHS))\n",
    "        f.write(\"LR = {} \\n\".format(hyp.LR))\n",
    "        f.write(\"HIDDEN_LAYERS = {} \\n\".format(HIDDEN))\n",
    "        f.write(\"ONE_HOT = {} \\n\".format(ONE_HOT))\n",
    "        f.write(\"DATA_AUG = {} \\n\".format(DATA_AUG))\n",
    "        f.write(\"Highest accuracy of {} occured at {}...\\nMinimum loss of {} occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        min_loss, store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    checkpoints = os.listdir(training_dir)\n",
    "    for checkpoint in checkpoints:\n",
    "        if \"checkpoint\" in checkpoint:\n",
    "            checkpoint_num = int(checkpoint[checkpoint.index(\"_\")+1:checkpoint.index(\".\")])\n",
    "            if checkpoint_num not in [store_qwk_epoch_loss_val.index(qwk_max_loss)+1,\n",
    "                                      store_epoch_loss_val.index(min_loss)+1,\n",
    "                                      store_epoch_acc_val.index(most_acc)+1]:\n",
    "                os.remove(training_dir+\"/\"+checkpoint)\n",
    "\n",
    "def train(model, HIDDEN, ONE_HOT, DATA_AUG, data_train_loader, data_val_loader):\n",
    "    print(\"Training...\")\n",
    "    training_dir = './training_{}+{}_{}_{}_{}'.format(ONE_HOT, DATA_AUG, len(HIDDEN), max(HIDDEN), time.time())\n",
    "    os.mkdir(training_dir)\n",
    "    os.mkdir(training_dir+'/misclassified')\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyp.LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    qwk_loss = cohen_kappa_score\n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    epoch = 0\n",
    "    store_epoch_loss = []\n",
    "    store_qwk_epoch_loss = []\n",
    "    store_epoch_loss_val = []\n",
    "    store_qwk_epoch_loss_val = []\n",
    "    store_epoch_acc_val = []\n",
    "    try:\n",
    "        for e in tqdm(range(hyp.EPOCHS)):\n",
    "            #scheduler.step()\n",
    "            epoch = e + 1\n",
    "            epoch_loss = 0\n",
    "            qwk_epoch_loss = 0\n",
    "            store_batch_loss = []\n",
    "            store_qwk_batch_loss = []\n",
    "            \n",
    "            for batch_num, (X, y) in enumerate(data_train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                batch_loss.backward()\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                optimizer.step()\n",
    "                store_batch_loss.append(batch_loss.clone().cpu())\n",
    "                store_qwk_batch_loss.append(qwk_batch_loss)\n",
    "                epoch_loss = torch.FloatTensor(store_batch_loss).mean()\n",
    "                qwk_epoch_loss = torch.FloatTensor(store_qwk_batch_loss).mean()\n",
    "                \n",
    "            store_epoch_loss.append(epoch_loss)\n",
    "            store_qwk_epoch_loss.append(qwk_epoch_loss)\n",
    "            torch.save(model.state_dict(), \"{}/checkpoint_{}.pth\".format(training_dir, epoch))\n",
    "\n",
    "            model.eval()\n",
    "            epoch_loss_val = 0\n",
    "            qwk_epoch_loss_val = 0\n",
    "            epoch_acc_val = 0\n",
    "            store_batch_loss_val = []\n",
    "            store_qwk_batch_loss_val = []\n",
    "            store_batch_acc_val = []\n",
    "            misclassified_images = []\n",
    "            for batch_num, (X, y) in enumerate(data_val_loader):\n",
    "                with torch.no_grad():\n",
    "                    prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                misclassified = prediction.max(-1)[-1].squeeze().cpu() != y.cpu()\n",
    "                misclassified_images.append(X[misclassified==1].cpu())\n",
    "                batch_acc = misclassified.float().mean()\n",
    "                store_batch_loss_val.append(batch_loss)\n",
    "                store_qwk_batch_loss_val.append(qwk_batch_loss)\n",
    "                store_batch_acc_val.append(batch_acc)\n",
    "                epoch_loss_val = torch.FloatTensor(store_batch_loss_val).mean()\n",
    "                qwk_epoch_loss_val = torch.FloatTensor(store_qwk_batch_loss_val).mean()\n",
    "                epoch_acc_val = torch.FloatTensor(store_batch_acc_val).mean()\n",
    "            store_epoch_loss_val.append(epoch_loss_val)\n",
    "            store_qwk_epoch_loss_val.append(qwk_epoch_loss_val)\n",
    "            store_epoch_acc_val.append(1-epoch_acc_val)\n",
    "            plt.plot(store_epoch_loss_val[1:], label=\"Validation Loss\")\n",
    "            plt.plot(store_qwk_epoch_loss_val[1:], label=\"Validation Metric(QWK)\")\n",
    "            plt.plot(store_epoch_acc_val[1:], label=\"Validation Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(\"{}/Loss.png\".format(training_dir))\n",
    "            plt.close()\n",
    "            if len(misclassified_images) > 0:\n",
    "                misclassified_images = np.concatenate(misclassified_images,axis=0)\n",
    "                validation_dir = training_dir+'/misclassified/checkpoint_{}'.format(epoch)\n",
    "                os.mkdir(validation_dir)\n",
    "            model.train()\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ONE_HOT in [0,1]: # for MaturitySize, FurLength, Health\n",
    "        for DATA_AUG in [0,1]: # for state data\n",
    "            data_train_loader, data_val_loader = prep.preprocess_data(ONE_HOT, DATA_AUG)\n",
    "            train(models.Model(hyp.HIDDEN_LIST[2], ONE_HOT, DATA_AUG).cuda(), hyp.HIDDEN_LIST[2], ONE_HOT, DATA_AUG, data_train_loader, data_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_v1]",
   "language": "python",
   "name": "conda-env-pytorch_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
