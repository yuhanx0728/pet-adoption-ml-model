{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/generic/THTensor.cpp:213",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1f400b62bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mHIDDEN_LIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIDDEN_LIST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mNUM_FOLDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_FOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AIforSocialGood/pet-adoption-prediction/preprocess_data.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(ONE_HOT, DATA_AUG)\u001b[0m\n\u001b[1;32m    212\u001b[0m                        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnColor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnColor3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                        \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# MaturitySize, FurLength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnVaccinated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnDewormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/generic/THTensor.cpp:213"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import hyp\n",
    "import models\n",
    "import state_data as aug\n",
    "import preprocess_data as prep\n",
    "\n",
    "\n",
    "def store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, NUM_FOLD, NUM_FOLDS, sub_training_dir):\n",
    "    most_acc = max(store_epoch_acc_val)\n",
    "    min_loss = min(store_epoch_loss_val)\n",
    "    qwk_max_loss = max(store_qwk_epoch_loss_val)\n",
    "    print(\"\\nHighest accuracy of {} occured at {}...\\nMinimum loss occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    with open(sub_training_dir+\"/HYP.txt\",\"w+\") as f:\n",
    "        f.write(\"EPOCH = {} \\n\".format(hyp.EPOCHS))\n",
    "        f.write(\"LR = {} \\n\".format(hyp.LR))\n",
    "        f.write(\"HIDDEN_LAYERS = {} \\n\".format(HIDDEN))\n",
    "        f.write(\"ONE_HOT = {} \\n\".format(ONE_HOT))\n",
    "        f.write(\"DATA_AUG = {} \\n\".format(DATA_AUG))\n",
    "        f.write(\"NUM_FOLDS = {}/{} \\n\".format(NUM_FOLD, NUM_FOLDS))\n",
    "        f.write(\"Highest accuracy of {} occured at {}...\\nMinimum loss of {} occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        min_loss, store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "#     checkpoints = os.listdir(sub_training_dir)\n",
    "#     for checkpoint in checkpoints:\n",
    "#         if \"checkpoint\" in checkpoint:\n",
    "#             checkpoint_num = int(checkpoint[checkpoint.index(\"_\")+1:checkpoint.index(\".\")])\n",
    "#             if checkpoint_num not in [store_qwk_epoch_loss_val.index(qwk_max_loss)+1,\n",
    "#                                       store_epoch_loss_val.index(min_loss)+1,\n",
    "#                                       store_epoch_acc_val.index(most_acc)+1]:\n",
    "#                 os.remove(sub_training_dir+\"/\"+checkpoint)\n",
    "\n",
    "\n",
    "def train_fold(model, HIDDEN, ONE_HOT, DATA_AUG, NUM_FOLD, NUM_FOLDS, data_train_loader, data_val_loader, sub_training_dir):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyp.LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    qwk_loss = cohen_kappa_score\n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    epoch = 0\n",
    "    store_epoch_loss = []\n",
    "    store_qwk_epoch_loss = []\n",
    "    store_epoch_loss_val = []\n",
    "    store_qwk_epoch_loss_val = []\n",
    "    store_epoch_acc_val = []\n",
    "    try:\n",
    "        for e in tqdm(range(hyp.EPOCHS)):\n",
    "            #scheduler.step()\n",
    "            epoch = e + 1\n",
    "            epoch_loss = 0\n",
    "            qwk_epoch_loss = 0\n",
    "            store_batch_loss = []\n",
    "            store_qwk_batch_loss = []\n",
    "            \n",
    "            for batch_num, (X, y) in enumerate(data_train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                batch_loss.backward()\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                optimizer.step()\n",
    "                store_batch_loss.append(batch_loss.clone().cpu())\n",
    "                store_qwk_batch_loss.append(qwk_batch_loss)\n",
    "                epoch_loss = torch.FloatTensor(store_batch_loss).mean()\n",
    "                qwk_epoch_loss = torch.FloatTensor(store_qwk_batch_loss).mean()\n",
    "                \n",
    "            store_epoch_loss.append(epoch_loss)\n",
    "            store_qwk_epoch_loss.append(qwk_epoch_loss)\n",
    "#             torch.save(model.state_dict(), \"{}/checkpoint_{}.pth\".format(sub_training_dir, epoch))\n",
    "\n",
    "            model.eval()\n",
    "            epoch_loss_val = 0\n",
    "            qwk_epoch_loss_val = 0\n",
    "            epoch_acc_val = 0\n",
    "            store_batch_loss_val = []\n",
    "            store_qwk_batch_loss_val = []\n",
    "            store_batch_acc_val = []\n",
    "            misclassified_images = []\n",
    "            for batch_num, (X, y) in enumerate(data_val_loader):\n",
    "                with torch.no_grad():\n",
    "                    prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                misclassified = prediction.max(-1)[-1].squeeze().cpu() != y.cpu()\n",
    "                misclassified_images.append(X[misclassified==1].cpu())\n",
    "                batch_acc = misclassified.float().mean()\n",
    "                store_batch_loss_val.append(batch_loss)\n",
    "                store_qwk_batch_loss_val.append(qwk_batch_loss)\n",
    "                store_batch_acc_val.append(batch_acc)\n",
    "                epoch_loss_val = torch.FloatTensor(store_batch_loss_val).mean()\n",
    "                qwk_epoch_loss_val = torch.FloatTensor(store_qwk_batch_loss_val).mean()\n",
    "                epoch_acc_val = torch.FloatTensor(store_batch_acc_val).mean()\n",
    "            store_epoch_loss_val.append(epoch_loss_val)\n",
    "            store_qwk_epoch_loss_val.append(qwk_epoch_loss_val)\n",
    "            store_epoch_acc_val.append(1-epoch_acc_val) # 1 - % of misclassified cases\n",
    "            plt.plot(store_epoch_loss_val[1:], label=\"Validation Loss\")\n",
    "            plt.plot(store_qwk_epoch_loss_val[1:], label=\"Validation Metric(QWK)\")\n",
    "            plt.plot(store_epoch_acc_val[1:], label=\"Validation Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(\"{}/Loss.png\".format(sub_training_dir))\n",
    "            plt.close()\n",
    "#             if len(misclassified_images) > 0:\n",
    "#                 misclassified_images = np.concatenate(misclassified_images,axis=0)\n",
    "#                 validation_dir = sub_training_dir+'/misclassified/checkpoint_{}'.format(epoch)\n",
    "#                 os.mkdir(validation_dir)\n",
    "            model.train()\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, NUM_FOLD, NUM_FOLDS, sub_training_dir)\n",
    "        return store_qwk_epoch_loss_val, store_epoch_loss_val, store_epoch_acc_val\n",
    "    except KeyboardInterrupt:\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, NUM_FOLD, NUM_FOLDS, sub_training_dir)\n",
    "        return store_qwk_epoch_loss_val, store_epoch_loss_val, store_epoch_acc_val\n",
    "\n",
    "\n",
    "def train(HIDDEN_LIST, ONE_HOT, DATA_AUG, NUM_FOLDS, data_loader):\n",
    "    print(\"Training...\"+\"HIDDEN_LIST/ONE_HOT/DATA_AUG/NUM_FOLDS\", str(HIDDEN_LIST), ONE_HOT, DATA_AUG, NUM_FOLDS)\n",
    "    training_dir = './training_{}_{}+{}+{}+{}'.format(int(time.time()), ONE_HOT, DATA_AUG, len(HIDDEN_LIST), max(HIDDEN_LIST))\n",
    "    os.mkdir(training_dir)\n",
    "\n",
    "    qwk_loss = [None] * NUM_FOLDS\n",
    "    ce_loss = [None] * NUM_FOLDS\n",
    "    acc = [None] * NUM_FOLDS\n",
    "    for NUM_FOLD in range(NUM_FOLDS):\n",
    "        sub_training_dir = training_dir+'/'+str(NUM_FOLD)\n",
    "        os.mkdir(sub_training_dir)\n",
    "#         os.mkdir(sub_training_dir+'/misclassified')\n",
    "        data_train_loader, data_val_loader = prep.fold_divider(data_loader, NUM_FOLD, NUM_FOLDS)\n",
    "        qwk_loss[NUM_FOLD], ce_loss[NUM_FOLD], acc[NUM_FOLD] = train_fold(models.Model(HIDDEN_LIST, ONE_HOT, DATA_AUG).cuda(), HIDDEN_LIST, ONE_HOT, DATA_AUG, NUM_FOLD, NUM_FOLDS, data_train_loader, data_val_loader, sub_training_dir)        \n",
    "\n",
    "    avg_qwk_loss = torch.tensor(qwk_loss).mean(0).numpy().tolist()\n",
    "    avg_ce_loss = torch.tensor(ce_loss).mean(0).numpy().tolist()\n",
    "    avg_acc = torch.tensor(acc).mean(0).numpy().tolist()\n",
    "\n",
    "    plt.plot(avg_ce_loss[1:], label=\"Validation Loss\")\n",
    "    plt.plot(avg_qwk_loss[1:], label=\"Validation Metric(QWK)\")\n",
    "    plt.plot(avg_acc[1:], label=\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"{}/Avg_Loss.png\".format(training_dir))\n",
    "    plt.close()\n",
    "\n",
    "    most_acc = max(avg_acc)\n",
    "    min_loss = min(avg_ce_loss)\n",
    "    qwk_max_loss = max(avg_qwk_loss)\n",
    "    with open(training_dir+\"/HYP.txt\",\"w+\") as f:\n",
    "        f.write(\"EPOCH = {} \\n\".format(hyp.EPOCHS))\n",
    "        f.write(\"LR = {} \\n\".format(hyp.LR))\n",
    "        f.write(\"HIDDEN_LAYERS = {} \\n\".format(HIDDEN_LIST))\n",
    "        f.write(\"ONE_HOT = {} \\n\".format(ONE_HOT))\n",
    "        f.write(\"DATA_AUG = {} \\n\".format(DATA_AUG))\n",
    "        f.write(\"Highest avg accuracy of {} occured at {}...\\nMinimum avg loss of {} occured at {}... \\nMaximum avg QWK metric of {} occured at {}\".format(\n",
    "        most_acc, avg_acc.index(most_acc)+1, \n",
    "        min_loss, avg_ce_loss.index(min_loss)+1, \n",
    "        qwk_max_loss, avg_qwk_loss.index(qwk_max_loss)+1))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ONE_HOT in [0, 1]:\n",
    "        for DATA_AUG in [0, 1]:\n",
    "            HIDDEN_LIST = hyp.HIDDEN_LIST[1]\n",
    "            NUM_FOLDS = 10\n",
    "            data_loader = prep.preprocess_data(ONE_HOT, DATA_AUG)\n",
    "            train(HIDDEN_LIST, ONE_HOT, DATA_AUG, NUM_FOLDS, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_sentiment_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c2772196a902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_sentiment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RescuerID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PetID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_sentiment_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, random, models\n",
    "import torch.utils.data as data\n",
    "import state_data as aug\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, random, models, os, json\n",
    "import torch.utils.data as data\n",
    "import state_data as aug\n",
    "import preprocess_data as prep\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# df = prep.add_sentiment_data(df)\n",
    "\n",
    "df = df.drop(['Name', 'RescuerID', 'PetID', 'Description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aa2b40c15d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "a = d[:,8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d[:,1].view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14993, 1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.FloatTensor(nType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14993, 2])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/generic/THTensorMoreMath.cpp:1298",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-67b5a83cb469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/generic/THTensorMoreMath.cpp:1298"
     ]
    }
   ],
   "source": [
    "Y = torch.cat([a,b], dim=0).cuda() # Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_v1]",
   "language": "python",
   "name": "conda-env-pytorch_v1-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
