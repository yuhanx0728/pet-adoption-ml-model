{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:10<45:12,  2.72s/it]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'store_epoch_acc_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3fd8d20c83e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, HIDDEN, ONE_HOT, DATA_AUG, data_train_loader, data_val_loader)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                           weights=\"quadratic\")\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mstore_batch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_v1/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3fd8d20c83e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mDATA_AUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for state data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mdata_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIDDEN_LIST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIDDEN_LIST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c3fd8d20c83e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, HIDDEN, ONE_HOT, DATA_AUG, data_train_loader, data_val_loader)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_epoch_loss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mqwk_max_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_qwk_epoch_loss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mstore_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqwk_max_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c3fd8d20c83e>\u001b[0m in \u001b[0;36mstore_result\u001b[0;34m(most_acc, min_loss, qwk_max_loss, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstore_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqwk_max_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_AUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     print(\"\\nHighest accuracy of {} occured at {}...\\nMinimum loss occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmost_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_epoch_acc_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mstore_epoch_loss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'store_epoch_acc_val' is not defined"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import hyp\n",
    "import models\n",
    "import state_data as aug\n",
    "import preprocess_data as prep\n",
    "\n",
    "def store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir):\n",
    "    most_acc = max(store_epoch_acc_val)\n",
    "    min_loss = min(store_epoch_loss_val)\n",
    "    qwk_max_loss = max(store_qwk_epoch_loss_val)\n",
    "    print(\"\\nHighest accuracy of {} occured at {}...\\nMinimum loss occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    with open(training_dir+\"/HYP.txt\",\"w+\") as f:\n",
    "        f.write(\"EPOCH = {} \\n\".format(hyp.EPOCHS))\n",
    "        f.write(\"LR = {} \\n\".format(hyp.LR))\n",
    "        f.write(\"HIDDEN_LAYERS = {} \\n\".format(HIDDEN))\n",
    "        f.write(\"ONE_HOT = {} \\n\".format(ONE_HOT))\n",
    "        f.write(\"DATA_AUG = {} \\n\".format(DATA_AUG))\n",
    "        f.write(\"Highest accuracy of {} occured at {}...\\nMinimum loss of {} occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        min_loss, store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    checkpoints = os.listdir(training_dir)\n",
    "    for checkpoint in checkpoints:\n",
    "        if \"checkpoint\" in checkpoint:\n",
    "            checkpoint_num = int(checkpoint[checkpoint.index(\"_\")+1:checkpoint.index(\".\")])\n",
    "            if checkpoint_num not in [store_qwk_epoch_loss_val.index(qwk_max_loss)+1,\n",
    "                                      store_epoch_loss_val.index(min_loss)+1,\n",
    "                                      store_epoch_acc_val.index(most_acc)+1]:\n",
    "                os.remove(training_dir+\"/\"+checkpoint)\n",
    "\n",
    "def train(model, HIDDEN, ONE_HOT, DATA_AUG, data_train_loader, data_val_loader):\n",
    "    print(\"Training...\")\n",
    "    training_dir = './training_{}+{}_{}_{}_{}'.format(ONE_HOT, DATA_AUG, len(HIDDEN), max(HIDDEN), time.time())\n",
    "    os.mkdir(training_dir)\n",
    "    os.mkdir(training_dir+'/misclassified')\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyp.LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    qwk_loss = cohen_kappa_score\n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    epoch = 0\n",
    "    store_epoch_loss = []\n",
    "    store_qwk_epoch_loss = []\n",
    "    store_epoch_loss_val = []\n",
    "    store_qwk_epoch_loss_val = []\n",
    "    store_epoch_acc_val = []\n",
    "    try:\n",
    "        for e in tqdm(range(hyp.EPOCHS)):\n",
    "            #scheduler.step()\n",
    "            epoch = e + 1\n",
    "            epoch_loss = 0\n",
    "            qwk_epoch_loss = 0\n",
    "            store_batch_loss = []\n",
    "            store_qwk_batch_loss = []\n",
    "            \n",
    "            for batch_num, (X, y) in enumerate(data_train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                batch_loss.backward()\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                optimizer.step()\n",
    "                store_batch_loss.append(batch_loss.clone().cpu())\n",
    "                store_qwk_batch_loss.append(qwk_batch_loss)\n",
    "                epoch_loss = torch.FloatTensor(store_batch_loss).mean()\n",
    "                qwk_epoch_loss = torch.FloatTensor(store_qwk_batch_loss).mean()\n",
    "                \n",
    "            store_epoch_loss.append(epoch_loss)\n",
    "            store_qwk_epoch_loss.append(qwk_epoch_loss)\n",
    "            torch.save(model.state_dict(), \"{}/checkpoint_{}.pth\".format(training_dir, epoch))\n",
    "\n",
    "            model.eval()\n",
    "            epoch_loss_val = 0\n",
    "            qwk_epoch_loss_val = 0\n",
    "            epoch_acc_val = 0\n",
    "            store_batch_loss_val = []\n",
    "            store_qwk_batch_loss_val = []\n",
    "            store_batch_acc_val = []\n",
    "            misclassified_images = []\n",
    "            for batch_num, (X, y) in enumerate(data_val_loader):\n",
    "                with torch.no_grad():\n",
    "                    prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                misclassified = prediction.max(-1)[-1].squeeze().cpu() != y.cpu()\n",
    "                misclassified_images.append(X[misclassified==1].cpu())\n",
    "                batch_acc = misclassified.float().mean()\n",
    "                store_batch_loss_val.append(batch_loss)\n",
    "                store_qwk_batch_loss_val.append(qwk_batch_loss)\n",
    "                store_batch_acc_val.append(batch_acc)\n",
    "                epoch_loss_val = torch.FloatTensor(store_batch_loss_val).mean()\n",
    "                qwk_epoch_loss_val = torch.FloatTensor(store_qwk_batch_loss_val).mean()\n",
    "                epoch_acc_val = torch.FloatTensor(store_batch_acc_val).mean()\n",
    "            store_epoch_loss_val.append(epoch_loss_val)\n",
    "            store_qwk_epoch_loss_val.append(qwk_epoch_loss_val)\n",
    "            store_epoch_acc_val.append(1-epoch_acc_val)\n",
    "            plt.plot(store_epoch_loss_val[1:], label=\"Validation Loss\")\n",
    "            plt.plot(store_qwk_epoch_loss_val[1:], label=\"Validation Metric(QWK)\")\n",
    "            plt.plot(store_epoch_acc_val[1:], label=\"Validation Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(\"{}/Loss.png\".format(training_dir))\n",
    "            plt.close()\n",
    "            if len(misclassified_images) > 0:\n",
    "                misclassified_images = np.concatenate(misclassified_images,axis=0)\n",
    "                validation_dir = training_dir+'/misclassified/checkpoint_{}'.format(epoch)\n",
    "                os.mkdir(validation_dir)\n",
    "            model.train()\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ONE_HOT in [0,1]: # for MaturitySize, FurLength, Health\n",
    "        for DATA_AUG in [0,1]: # for state data\n",
    "            data_train_loader, data_val_loader = prep.preprocess_data(ONE_HOT, DATA_AUG)\n",
    "            train(models.Model(hyp.HIDDEN_LIST[2], ONE_HOT, DATA_AUG).cuda(), hyp.HIDDEN_LIST[2], ONE_HOT, DATA_AUG, data_train_loader, data_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in main function: 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 0 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<44:39,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.3918193578720093 occured at 1...\n",
      "Minimum loss of 1.364376187324524 occured at 1... \n",
      "Maximum QWK metric of 0.28678271174430847 occured at 1\n",
      "in main function: 0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 0 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<43:26,  2.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.24059295654296875 occured at 1...\n",
      "Minimum loss of 1.531187653541565 occured at 1... \n",
      "Maximum QWK metric of -0.04076163470745087 occured at 1\n",
      "in main function: 1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 1 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<43:02,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.35421591997146606 occured at 1...\n",
      "Minimum loss of 1.3958059549331665 occured at 1... \n",
      "Maximum QWK metric of 0.26124417781829834 occured at 1\n",
      "in main function: 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in model: 1 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1000 [00:02<42:35,  2.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest accuracy of 0.29395681619644165 occured at 1...\n",
      "Minimum loss of 1.5496681928634644 occured at 1... \n",
      "Maximum QWK metric of -0.017652668058872223 occured at 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_v1]",
   "language": "python",
   "name": "conda-env-pytorch_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
