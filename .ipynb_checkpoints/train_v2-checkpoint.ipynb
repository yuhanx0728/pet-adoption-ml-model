{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, random, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import hyp\n",
    "import models\n",
    "import state_data as aug\n",
    "import preprocess_data as prep\n",
    "\n",
    "def store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir):\n",
    "    most_acc = max(store_epoch_acc_val)\n",
    "    min_loss = min(store_epoch_loss_val)\n",
    "    qwk_max_loss = max(store_qwk_epoch_loss_val)\n",
    "    print(\"\\nHighest accuracy of {} occured at {}...\\nMinimum loss occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    with open(training_dir+\"/HYP.txt\",\"w+\") as f:\n",
    "        f.write(\"EPOCH = {} \\n\".format(hyp.EPOCHS))\n",
    "        f.write(\"LR = {} \\n\".format(hyp.LR))\n",
    "        f.write(\"HIDDEN_LAYERS = {} \\n\".format(HIDDEN))\n",
    "        f.write(\"ONE_HOT = {} \\n\".format(ONE_HOT))\n",
    "        f.write(\"DATA_AUG = {} \\n\".format(DATA_AUG))\n",
    "        f.write(\"Highest accuracy of {} occured at {}...\\nMinimum loss of {} occured at {}... \\nMaximum QWK metric of {} occured at {}\".format(\n",
    "        most_acc, store_epoch_acc_val.index(most_acc)+1, \n",
    "        min_loss, store_epoch_loss_val.index(min_loss)+1, \n",
    "        qwk_max_loss, store_qwk_epoch_loss_val.index(qwk_max_loss)+1))\n",
    "    checkpoints = os.listdir(training_dir)\n",
    "    for checkpoint in checkpoints:\n",
    "        if \"checkpoint\" in checkpoint:\n",
    "            checkpoint_num = int(checkpoint[checkpoint.index(\"_\")+1:checkpoint.index(\".\")])\n",
    "            if checkpoint_num not in [store_qwk_epoch_loss_val.index(qwk_max_loss)+1,\n",
    "                                      store_epoch_loss_val.index(min_loss)+1,\n",
    "                                      store_epoch_acc_val.index(most_acc)+1]:\n",
    "                os.remove(training_dir+\"/\"+checkpoint)\n",
    "\n",
    "def train(model, HIDDEN, ONE_HOT, DATA_AUG, NUM_FOLDS, data_train_loader, data_val_loader):\n",
    "    print(\"Training...\")\n",
    "    training_dir = './training_{}_{}+{}+{}+{}'.format(int(time.time()), ONE_HOT, DATA_AUG, len(HIDDEN), max(HIDDEN))\n",
    "    os.mkdir(training_dir)\n",
    "    os.mkdir(training_dir+'/misclassified')\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyp.LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    qwk_loss = cohen_kappa_score\n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    epoch = 0\n",
    "    store_epoch_loss = []\n",
    "    store_qwk_epoch_loss = []\n",
    "    store_epoch_loss_val = []\n",
    "    store_qwk_epoch_loss_val = []\n",
    "    store_epoch_acc_val = []\n",
    "    try:\n",
    "        for e in tqdm(range(hyp.EPOCHS)):\n",
    "            #scheduler.step()\n",
    "            epoch = e + 1\n",
    "            epoch_loss = 0\n",
    "            qwk_epoch_loss = 0\n",
    "            store_batch_loss = []\n",
    "            store_qwk_batch_loss = []\n",
    "            \n",
    "            for batch_num, (X, y) in enumerate(data_train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                batch_loss.backward()\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                optimizer.step()\n",
    "                store_batch_loss.append(batch_loss.clone().cpu())\n",
    "                store_qwk_batch_loss.append(qwk_batch_loss)\n",
    "                epoch_loss = torch.FloatTensor(store_batch_loss).mean()\n",
    "                qwk_epoch_loss = torch.FloatTensor(store_qwk_batch_loss).mean()\n",
    "                \n",
    "            store_epoch_loss.append(epoch_loss)\n",
    "            store_qwk_epoch_loss.append(qwk_epoch_loss)\n",
    "            torch.save(model.state_dict(), \"{}/checkpoint_{}.pth\".format(training_dir, epoch))\n",
    "\n",
    "            model.eval()\n",
    "            epoch_loss_val = 0\n",
    "            qwk_epoch_loss_val = 0\n",
    "            epoch_acc_val = 0\n",
    "            store_batch_loss_val = []\n",
    "            store_qwk_batch_loss_val = []\n",
    "            store_batch_acc_val = []\n",
    "            misclassified_images = []\n",
    "            for batch_num, (X, y) in enumerate(data_val_loader):\n",
    "                with torch.no_grad():\n",
    "                    prediction = model.forward(X.cuda())\n",
    "                batch_loss = ce_loss(prediction, y)\n",
    "                qwk_batch_loss = qwk_loss(y.clone().detach().cpu().numpy(), \n",
    "                                          np.argmax(prediction.clone().detach().cpu().numpy(), axis=1), \n",
    "                                          weights=\"quadratic\")\n",
    "                misclassified = prediction.max(-1)[-1].squeeze().cpu() != y.cpu()\n",
    "                misclassified_images.append(X[misclassified==1].cpu())\n",
    "                batch_acc = misclassified.float().mean()\n",
    "                store_batch_loss_val.append(batch_loss)\n",
    "                store_qwk_batch_loss_val.append(qwk_batch_loss)\n",
    "                store_batch_acc_val.append(batch_acc)\n",
    "                epoch_loss_val = torch.FloatTensor(store_batch_loss_val).mean()\n",
    "                qwk_epoch_loss_val = torch.FloatTensor(store_qwk_batch_loss_val).mean()\n",
    "                epoch_acc_val = torch.FloatTensor(store_batch_acc_val).mean()\n",
    "            store_epoch_loss_val.append(epoch_loss_val)\n",
    "            store_qwk_epoch_loss_val.append(qwk_epoch_loss_val)\n",
    "            store_epoch_acc_val.append(1-epoch_acc_val)\n",
    "            plt.plot(store_epoch_loss_val[1:], label=\"Validation Loss\")\n",
    "            plt.plot(store_qwk_epoch_loss_val[1:], label=\"Validation Metric(QWK)\")\n",
    "            plt.plot(store_epoch_acc_val[1:], label=\"Validation Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(\"{}/Loss.png\".format(training_dir))\n",
    "            plt.close()\n",
    "            if len(misclassified_images) > 0:\n",
    "                misclassified_images = np.concatenate(misclassified_images,axis=0)\n",
    "                validation_dir = training_dir+'/misclassified/checkpoint_{}'.format(epoch)\n",
    "                os.mkdir(validation_dir)\n",
    "            model.train()\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        store_result(store_epoch_acc_val, store_epoch_loss_val, store_qwk_epoch_loss_val, HIDDEN, ONE_HOT, DATA_AUG, training_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ONE_HOT in [0,1]: # for MaturitySize, FurLength, Health\n",
    "        for DATA_AUG in [0,1]: # for state data\n",
    "            for HIDDEN_LIST in hyp.HIDDEN_LIST:\n",
    "                for NUM_FOLDS in [5, 10]:\n",
    "                    data_train_loader, data_val_loader = prep.preprocess_data(ONE_HOT, DATA_AUG)\n",
    "                    train(models.Model(HIDDEN_LIST, ONE_HOT, DATA_AUG).cuda(), HIDDEN_LIST, ONE_HOT, DATA_AUG, NUM_FOLDS, data_train_loader, data_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch, random, models\n",
    "import torch.utils.data as data\n",
    "import state_data as aug\n",
    "\n",
    "ONE_HOT = 0\n",
    "DATA_AUG = 1\n",
    "dir = \"data/train_sentiment\"\n",
    "        \n",
    "df = pd.read_csv('data/train.csv')\n",
    "nPetID = df['PetID']\n",
    "df = df.drop(['Name', 'RescuerID', 'PetID', 'Description'], axis=1)\n",
    "d = torch.FloatTensor(df.values)\n",
    "\n",
    "# Type,Name,Age,Breed1,Breed2,Gender,Color1,Color2,Color3,MaturitySize,\n",
    "#    0,   x,  1,     2,     3,     4,     5,     6,     7,           8,\n",
    "# FurLength,Vaccinated,Dewormed,Sterilized,Health,Quantity,Fee,State,RescuerID,\n",
    "#         9,        10,      11,        12,    13,      14, 15,   16,        x,      \n",
    "# VideoAmt,Description,PetID,PhotoAmt,AdoptionSpeed\n",
    "#       17,          x,    x,      18,           19\n",
    "\n",
    "# df['Type']\n",
    "nType = np.array([[0.5,0.5]]*d.size(0)).astype(float)\n",
    "nType[df['Type'].values.astype(int)==1] = [0.,1.]\n",
    "nType[df['Type'].values.astype(int)==2] = [1.,0.]\n",
    "\n",
    "# df['Breed1']\n",
    "idx = d[:,2]\n",
    "nBreed1 = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "\n",
    "# df['Breed2']\n",
    "idx = d[:,3]\n",
    "nBreed2 = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "\n",
    "# df['Gender']\n",
    "nGender = np.array([[0.5,0.5]]*d.size(0)).astype(float)\n",
    "nGender[df['Gender'].values.astype(int)==1] = [0.,1.]\n",
    "nGender[df['Gender'].values.astype(int)==2] = [1.,0.]\n",
    "\n",
    "# df['Color1']\n",
    "idx = d[:,5]\n",
    "nColor1 = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "\n",
    "# df['Color2']\n",
    "idx = d[:,6]\n",
    "nColor2 = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "\n",
    "# df['Color3']\n",
    "idx = d[:,7]\n",
    "nColor3 = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "\n",
    "# df['Vaccinated']\n",
    "nVaccinated = np.array([[0.5,0.5]]*d.size(0)).astype(float)\n",
    "nVaccinated[df['Vaccinated'].values.astype(int)==1] = [0.,1.]\n",
    "nVaccinated[df['Vaccinated'].values.astype(int)==2] = [1.,0.]\n",
    "\n",
    "# df['Dewormed']\n",
    "nDewormed = np.array([[0.5,0.5]]*d.size(0)).astype(float)\n",
    "nDewormed[df['Dewormed'].values.astype(int)==1] = [0.,1.]\n",
    "nDewormed[df['Dewormed'].values.astype(int)==2] = [1.,0.]\n",
    "\n",
    "# df['Sterilized']\n",
    "nSterilized = np.array([[0.5,0.5]]*d.size(0)).astype(float)\n",
    "nSterilized[df['Sterilized'].values.astype(int)==1] = [0.,1.]\n",
    "nSterilized[df['Sterilized'].values.astype(int)==2] = [1.,0.]\n",
    "\n",
    "# df['State']\n",
    "idx = d[:,16]\n",
    "nState = torch.zeros(len(idx), int(idx.max()-idx.min())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1)-idx.min(), 1.)\n",
    "\n",
    "# sentiment analysis\n",
    "# if no textual description available, 0 for sentimental analysis column\n",
    "nSentiment = np.array([[0]]*d.size(0)).astype(float)\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    petid = file[:file.index(\".\")]\n",
    "    print(petid)\n",
    "    with open(dir+\"/\"+file) as f:\n",
    "        data = json.load(f)\n",
    "        mag = data[\"documentSentiment\"][\"magnitude\"]\n",
    "        score = data[\"documentSentiment\"][\"score\"]\n",
    "        df.loc[nPetID == petid] == mag*score\n",
    "print(df[])\n",
    "if DATA_AUG:\n",
    "    state_data = {}\n",
    "    for k, v in aug.state_gdp.items():\n",
    "        state_data[k] = np.array([v, aug.state_population[k], aug.state_area[k]]).astype(float)\n",
    "\n",
    "    nState = np.array([[0, 0, 0]]*d.size(0)).astype(float)\n",
    "    for k,v in state_data.items():\n",
    "        nState[df['State'].values.astype(int)==k] = v\n",
    "\n",
    "if ONE_HOT:\n",
    "    idx = d[:,8]\n",
    "    nMaturitySize = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "    idx = d[:,9]\n",
    "    nFurLength = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "    idx = d[:,13]\n",
    "    nHealth = torch.zeros(len(idx), int(idx.max())+1).scatter_(1, idx.view(len(idx)).long().unsqueeze(1), 1.)[:,1:]\n",
    "    d = torch.cat([torch.FloatTensor(nType),\n",
    "                   d[:,1:2],\n",
    "                   torch.FloatTensor(nBreed1),\n",
    "                   torch.FloatTensor(nBreed2),\n",
    "                   torch.FloatTensor(nGender),\n",
    "                   torch.FloatTensor(nColor1),\n",
    "                   torch.FloatTensor(nColor2),\n",
    "                   torch.FloatTensor(nColor3),\n",
    "                   torch.FloatTensor(nMaturitySize),\n",
    "                   torch.FloatTensor(nFurLength),\n",
    "                   torch.FloatTensor(nVaccinated),\n",
    "                   torch.FloatTensor(nDewormed),\n",
    "                   torch.FloatTensor(nSterilized),\n",
    "                   torch.FloatTensor(nHealth),\n",
    "                   d[:,13:16],\n",
    "                   torch.FloatTensor(nState),\n",
    "                   d[:,17:]\n",
    "                  ], dim=1).cuda()\n",
    "else:\n",
    "    d = torch.cat([torch.FloatTensor(nType),\n",
    "                   d[:,1:2],\n",
    "                   torch.FloatTensor(nBreed1),\n",
    "                   torch.FloatTensor(nBreed2),\n",
    "                   torch.FloatTensor(nGender),\n",
    "                   torch.FloatTensor(nColor1),\n",
    "                   torch.FloatTensor(nColor2),\n",
    "                   torch.FloatTensor(nColor3),\n",
    "                   d[:,8:10],\n",
    "                   torch.FloatTensor(nVaccinated),\n",
    "                   torch.FloatTensor(nDewormed),\n",
    "                   torch.FloatTensor(nSterilized),\n",
    "                   d[:,14:16],\n",
    "                   torch.FloatTensor(nState),\n",
    "                   d[:,17:]\n",
    "                  ], dim=1).cuda()\n",
    "\n",
    "random.shuffle(d)\n",
    "partition = {}\n",
    "validation = d[:len(d)//10]\n",
    "partition['validation'] = models.CSVDataset(validation)\n",
    "train_set = d[len(d)//10:]\n",
    "partition['train'] = models.CSVDataset(train_set)\n",
    "data_train_loader = data.DataLoader(partition['train'], shuffle=True, batch_size=32)\n",
    "data_val_loader = data.DataLoader(partition['validation'], batch_size=32)\n",
    "return data_train_loader, data_val_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_v1]",
   "language": "python",
   "name": "conda-env-pytorch_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
